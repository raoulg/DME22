{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer_data.csv', index_col=\"id\")\n",
    "X = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore & preprocess\n",
    "Explore the data a bit, to know if the data needs preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X_train.melt()\n",
    "sns.boxplot(data=p, x='variable', y='value')\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(X_train).melt()\n",
    "sns.boxplot(data=p, x='variable', y='value')\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions: the data needs some rescaling. We could dive into the data, trying to get a better grip on correlations etc., but that is another lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select models and compare performance\n",
    "Now select some models. Before you try them, try to guess what models would work better on this dataset, and which models will probably works worse. This way, you can improve your own priors about some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "cv = 5\n",
    "classifiers = [\n",
    "    ('svc-linear', SVC(kernel='linear')),\n",
    "    ('svc-kernel', SVC()),\n",
    "    ('random-forest', RandomForestClassifier()),\n",
    "    ('naive bayes', GaussianNB()),\n",
    "    ('gaussian', GaussianProcessClassifier()),\n",
    "    ('kNN', KNeighborsClassifier(3)),\n",
    "    ('decision tree', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "for i, (name, clf) in enumerate(classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = cross_val_score(clf, X_test, y_test, cv = cv, scoring='f1_macro')\n",
    "\n",
    "    mu = np.mean(result)\n",
    "    stderr = np.std(result)/np.sqrt(cv)\n",
    "\n",
    "    plt.scatter(i, mu, label=name)\n",
    "    plt.errorbar(i, mu, yerr=stderr)\n",
    "    plt.legend(loc=3)\n",
    "\n",
    "plt.xticks(np.arange(len(classifiers)), [name[0] for name in classifiers], rotation=45);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "Pick one model, and make a more extensive evaluation of the performance by making a precision-recall curve, roc curve and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in classifiers:\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        print(\"decision_function:{}\".format(name))\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        print(\"predict_proba:{}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianProcessClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = clf.predict_proba(X_test)\n",
    "y_test[:5], proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we will need to transform the `y_test`. Let's do that simply with `y_test == \"B\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_decision = cross_val_predict(clf, X_test, y_test, cv = 3, n_jobs = 4, method = 'predict_proba')\n",
    "precision, recall, thresholds = precision_recall_curve(y_test == 'B', y_decision[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "data = pd.DataFrame({'precision':precision[:-1],'recall': recall[:-1], 'thresholds':thresholds})\n",
    "sns.lineplot(x = 'thresholds', y='precision', label = 'precision', data = data)\n",
    "sns.lineplot(x = 'thresholds', y='recall', label = 'recall', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test == 'B', y_decision[:,0])\n",
    "data = pd.DataFrame({'fpr' : fpr, 'tpr':tpr})\n",
    "plot = sns.lineplot(x = 'fpr', y = 'tpr', data=data)\n",
    "plot.set(xlabel = 'FPR', ylabel = 'TPR')\n",
    "plt.plot([0,1], [0,1], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "cfm = confusion_matrix(y_test, yhat)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
